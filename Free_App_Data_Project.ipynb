{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FREE APP DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the project: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project simulates working as data analyst for a company that builds Android and iOS mobile apps. The company makes apps available on Google Play and in the App Store. They only build apps that are free to download and install, and the main source of revenue consists of in-app ads. This means that the number of users of their apps determines revenue for any given app â€” the more users who see and engage with the ads, the better. The goal for this project is to analyze data to help the developers understand what type of apps are likely to attract more users. \n",
    "\n",
    "As of September 2018, there were approximately 2 million iOS apps available on the App Store, and 2.1 million Android apps on Google Play.\n",
    "\n",
    "- **STYLE/FORMATTING NOTE: The format of the content below is block of code first, followed by printed result, followed by a markdown explaining the code above and why it was ran. The markdown block will also provide any insights or notable discoveries in the processed data.**\n",
    "\n",
    "- The process below is broken down into two main sections with numerous sub-sections. The two main sections are:\n",
    "    1. Data Cleaning Process: I clean the data to eliminate all paid apps, non-english apps, incomplete rows, and duplicate entries. Each subsection is a \"Step\" in the cleaning process. \n",
    "    2. Data Analysis Process: after the data is clean, I run various functions to determine useful information from the raw data such as popular genres and which genres have the most users. Each sub-seciton is a \"step\" in the process\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data Cleaning Process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: start with a function that will make it easy to print readable rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(data_set, start, end, rows_and_columns=False):\n",
    "    data_slice = data_set[start:end] \n",
    "    for row in data_slice: \n",
    "        print(row)\n",
    "        print('\\n') #starts a new line\n",
    "    \n",
    "    if rows_and_columns: \n",
    "        print('Number of rows', len(data_set))\n",
    "        print('Number of columns', len(data_set[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above takes in a data set, start and end for the splice of the list I want. \n",
    "Then I initialize a new data slice variable called data_slice. Next, I iterate over the data slice to print out the number of rows and columns in the original dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: import both csv files (google and app store) and save as list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "google_data = open('/home/hunter/Jupyter Projects/1.free_app_proj/googleplaystore.csv')\n",
    "read_google = csv.reader(google_data)\n",
    "gdl = list(read_google)\n",
    "\n",
    "apple_data = open('/home/hunter/Jupyter Projects/1.free_app_proj/AppleStore (1).csv')\n",
    "read_apple = csv.reader(apple_data)\n",
    "adl = list(read_apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, I imported csv module to be able to use the reader function after opening the csv file. Once the file was opened, the program read the file then turned it into a list, which will be used for all subsequent operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: take a look at the data to become familiar with how it is presented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows 10842\n",
      "Number of columns 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(gdl, 0, 2, rows_and_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows 7198\n",
      "Number of columns 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(adl, 0, 2, rows_and_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Above we found that both lists have similar data but are not the same. This is important to pay attention to as we go forward in the project to make sure we are calling the correct indexes for each list. \n",
    "\n",
    "It is also important to note that we did not remove the header when we created the list therefor whenever we call the original list or define a function, iterate over all rows except the header. \n",
    "\n",
    "Some features of the Google store list that are not in the Apple store list are category and genre, where as the Apple store only lists genre. This insight is important because the breakdown of category and and genre can give more fidelity into which category/genre the company should build their test app. Also, the google store tracks number of installations which is important because it gives an accurate insight into how many users have the app n their phone. The Apply store does not have this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Clean the data. We need to remove any apps that are not free or are not English language apps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to determine if any rows in the lists are incomplete:\n",
    "def incomplete_row(a_list):\n",
    "    for row in a_list[1:]:\n",
    "        if len(row) != len(a_list[0]):\n",
    "            print('Incomplete row:', a_list.index(row))\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The function `incomplete_row` iterates over the called list and measures the length of the row, and compares it to the length of the header. If there is a miss match, it lets us know the row has incomplete data in it. When we print both header and the incomplete row, we can determine which piece of information is missing. Additionally, the index of the row of incomplete is printed so I can delete it from the list in the next code block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomplete row: 10473\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n"
     ]
    }
   ],
   "source": [
    "#look for incomplete data rows by comparing the length of each row to the header:\n",
    "incomplete_row(gdl)\n",
    "print('\\n')\n",
    "print(gdl[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_row(adl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running both adl and gdl thorugh the `incomplete_row(a_list)` function we found:\n",
    "    **Google has 1 row** of incomplete data.\n",
    "    **App store has 0 rows** of incomplete data.\n",
    "      In the next code block I delete the row from `gdl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the row with missing data from `gdl`:\n",
    "del gdl[10473]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two functions below `dup_dict` and `duplicates` both do the same thing. They count up all the duplicates in each list. Both functions returned the same number of 1181 in the gdl list. Creating the two functions was redundant but I left them in for my own practice and reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function that will make a dictionary based on app name to look for duplicates:\n",
    "def dup_dict(a_list, a):\n",
    "    test_dict = {}\n",
    "    len_duplicates = 0\n",
    "    for row in a_list[1:]:\n",
    "        item = row[a]\n",
    "        if item in test_dict:\n",
    "            test_dict[item] += 1\n",
    "            len_duplicates += 1\n",
    "        else:\n",
    "            test_dict[item] = 1\n",
    "    return print('There is a total of:', len_duplicates, 'duplicates in the list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of: 0 duplicates in the list\n"
     ]
    }
   ],
   "source": [
    "dup_dict(adl, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of: 1181 duplicates in the list\n"
     ]
    }
   ],
   "source": [
    "dup_dict(gdl, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I created a function that looks for duplicate data. The function works in the following way:\n",
    "1. initiate an empty dictionary\n",
    "2. iterate over each row in the called list\n",
    "3. check to see if the app name is already in the dictionary. \n",
    "5. if the item is in the dictionary, increase the key's value by 1. \n",
    "6. if the item is not in the dictionary, set the key's value to 1. \n",
    "7. add duplicates to len_duplicates to find total. \n",
    "Function can be altered to return the dictionary of duplicates or print out all the duplicates and how many per app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to determine duplicates from lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function where we pull data from an index and assign it to a singular entry list or duplicates list:\n",
    "def duplicates(a_list, x): #x = index to pull data from\n",
    "    sing_entries = []\n",
    "    dup_entries = []\n",
    "    for row in a_list:\n",
    "        item = row[x]\n",
    "        if item in sing_entries: \n",
    "            dup_entries.append(item)\n",
    "        else: \n",
    "            sing_entries.append(item)\n",
    "    print('This list has', len(dup_entries), 'duplicate entries') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `duplicates()` listed above is just a redundant function to demonstrate another way to look for duplicates in the list. \n",
    "1. create two empty lists. One is for single entries, the other for duplicates\n",
    "2. iterate over the called list. \n",
    "3. assign the data in the index listed as a variable to `item`\n",
    "4. check to see if `item` is in the `sing_entries` list, if it is, then the item is a duplicate, so append it to the `dup_entries` list.\n",
    "5. otherwise, append the item to the `sing_entries` list.\n",
    "6. print out the length of the `dup_entries` list to get total duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This list has 1181 duplicate entries\n"
     ]
    }
   ],
   "source": [
    "duplicates(gdl, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This list has 0 duplicate entries\n"
     ]
    }
   ],
   "source": [
    "duplicates(adl, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we delete the duplicate data. We will determine which duplicate is the most accurate by choosing which has the highest and choose to keep that one, and delete all others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_dupes(a_list, x, y):\n",
    "    rating_dict = {}\n",
    "    clean_list = []\n",
    "    already_added = []\n",
    "    \n",
    "    for row in a_list[1:]:\n",
    "        app = row[x]\n",
    "        rating = int(row[y])\n",
    "        \n",
    "        if app in rating_dict and rating_dict[app] < rating:\n",
    "            rating_dict[app] = rating\n",
    "        elif app not in rating_dict:\n",
    "            rating_dict[app] = rating\n",
    "        if rating == rating_dict[app] and app not in already_added: #to prevent ratings that are equal creating duplicates in clean list\n",
    "            clean_list.append(row)\n",
    "            already_added.append(app)\n",
    "            \n",
    "    return clean_list   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above creates a dictionary and two lists and returns the `clean_list` which is the list without duplicates. \n",
    "1. iterate over the called list defined in the function. \n",
    "2. check to see if the app name is in the dictionary AND check to see if the key's variable is greater than the apps rating. \n",
    "3. if the if statement is true then append dictionary's key value to the current rating\n",
    "-- this ensures we save the duplicate row with the highest number of ratings. \n",
    "4. check to see if the rating is equal to the rating listed as the key's value AND that the app is not in the `already_added` list. \n",
    "-- Checking to see if the data is in `already_added` ensures that no duplicate data enters the `clean_data` in the event that there are duplicate rows that have identical data\n",
    "5. return the `clean_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n",
      "9659\n"
     ]
    }
   ],
   "source": [
    "#Run the function, check the length of the original list minus no. of duplicates vs. length of duplicates dictionary. \n",
    "gdl_clean = del_dupes(gdl, 0, 3)\n",
    "\n",
    "expected_length_gdl = len(gdl[1:]) - 1181\n",
    "print(expected_length_gdl)\n",
    "\n",
    "length_gdl_clean = len(gdl_clean)\n",
    "print(length_gdl_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we created a duplicate free list for `gdl` (`adl` did not have duplicates)\n",
    "Going forward we will only use the **`gel_clean` list NOT `gdl`**\n",
    "\n",
    "To determine if our function properly deleted the rows we found the length of the original `gdl` list and subtracted out the number of duplicates that we found earlier. The result gave us an expected length that we can check our new clean list against. \n",
    "\n",
    "Both length numbers matched, showing us we successfully deleted the duplicates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Remove all non-English entries.\n",
    "### Recall from the initial criteria, we are analyzing free apps that are in the english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all rows that are not in the english language\n",
    "#ASCII states that all english characters are within range 1-127\n",
    "#Start by creating two lists, iterate over the original data and assing rows to either english, or non_english lists. \n",
    "\n",
    "def is_english(string):\n",
    "    non_ascii = 0\n",
    "    \n",
    "    for character in string: \n",
    "        if ord(character) > 128:\n",
    "            non_ascii += 1\n",
    "      \n",
    "    if non_ascii > 3: \n",
    "        return False\n",
    "    else:\n",
    "        return True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we defined a function that will do the following: \n",
    "1. set a variable `non-ascii` to 0 to be used for counting characters outside the english lang. \n",
    "2. iterate over each letter in the app name. \n",
    "3. the iteration will ananyze each character in the string to see if it's ascii number value is greater than 128 (non-english characters)\n",
    "4. if true, add 1 to `non-ascii\n",
    "5. create a boolean expression to check if non_ascii is > 3 after the iteration is complete. \n",
    "    - we want to minimize data loss so we chose to eliminate characters that have more than 3 non english characters to account for things like emojis and dashes. \n",
    "6. the if statement will return a True or False. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9613\n",
      "-46\n"
     ]
    }
   ],
   "source": [
    "gdl_clean_eng = []\n",
    "\n",
    "for app in gdl_clean[1:]:    \n",
    "    name = app[0]\n",
    "    ed = is_english(name)\n",
    "    if ed == True:\n",
    "        gdl_clean_eng.append(app)\n",
    "\n",
    "print(len(gdl_clean_eng))\n",
    "print(len(gdl_clean_eng) - len(gdl_clean))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6183\n",
      "-1015\n"
     ]
    }
   ],
   "source": [
    "adl_clean_eng = []\n",
    "\n",
    "for app in adl[1:]:    \n",
    "    name = app[1]\n",
    "    ed = is_english(name)\n",
    "    if ed == True:\n",
    "        adl_clean_eng.append(app)\n",
    "\n",
    "print(len(adl_clean_eng))\n",
    "print(len(adl_clean_eng) - len(adl))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two code blocks above we iterated over our previously cleaned data (no duplicates and no incomplete rows). \n",
    "1. We initialized a new list for the english only data. \n",
    "2. iterate over the clean data list and assign the data at the index which holds the app name to `name`\n",
    "3. run the function `is_english(name)` to `ed`\n",
    "4. remember the `is_english` function returns a true or false. True if the word has engligh characters, false if not. \n",
    "5. if the return is True, append the row from the original list to the newly created list. \n",
    "6. the result is the newest version of the cleaned list. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Remove all non-free apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function to create two list of lists for free and non_free data\n",
    "def free_app(a_list, a):\n",
    "    free = []\n",
    "    not_free = []\n",
    "    \n",
    "    for row in a_list:\n",
    "        price = row[a]\n",
    "        dollar = float(price)\n",
    "        if dollar == 0.0: \n",
    "            free.append(row)\n",
    "        else: \n",
    "            not_free.append(row)\n",
    "            \n",
    "    return free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above we created a function that separates the data from the main list into two separate lists. One list for free apps and one for non-free apps. \n",
    "1. we define the function `free_app()`\n",
    "2. initialize 2 lists: `non_free` and `free`\n",
    "3. iterate over the list and name a variable that will be the index of the data we want. \n",
    "4. let data be the data in the index we named with the variable. convert string to float\n",
    "5. if the data = 0 then it is free. \n",
    "    - append to free list\n",
    "    - else append to non_free list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adl_total_clean = free_app(adl_clean_eng, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove the'$' from the cost in each row of gdl list to allow float conversion\n",
    "for row in gdl_clean_eng:\n",
    "    money = row[7]\n",
    "    dol = money.replace('$', '')\n",
    "    row[7] = dol\n",
    "\n",
    "#now run `gdl_clean` through the `free_app` function\n",
    "gdl_total_clean = free_app(gdl_clean_eng, 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two code cells above we ran our clean, english only data through the function that sorted rown into free and paid lists. We checked each list for accuracy to ensure the sum of the length of the two lists was equal to the total length of the original list. \n",
    "\n",
    "**The clean list going forward will be `adl_total_clean` and `gdl_total_clean`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion to data cleaning process:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far to clean the data, we did the following\n",
    "- found and deleted incomplete rows\n",
    "- removed duplicate data rows\n",
    "- filtered out the majority of non-english apps (this needs to be optimized because we did lost good data while keeping some bad data in the lists.)\n",
    "- filtered out apps that are not free "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the company: Our goal is to determine the kinds of apps that are likely to attract more users because the number of people using our apps affect our revenue.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea has three steps:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, we develop it further.\n",
    "3. If the app is profitable after six months, we build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "In order to achieve these goals we need to figure out which type of app will be successful in both the Google and Apple store. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Determine the most common genres between the two stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will set up a function that makes a dictionary used as a frequency table and we will list the top three genres for both Google and Apple app stores\n",
    "\n",
    "def pop_genres(dataset, index): #this function returns a freq table for genres\n",
    "    total = len(dataset)\n",
    "    genre_dict = {}\n",
    "    \n",
    "    for row in dataset: #create a dictionary with values as intergers\n",
    "        genre = row[index]\n",
    "        if genre in genre_dict:\n",
    "            genre_dict[genre] += 1\n",
    "        else:\n",
    "            genre_dict[genre] = 1\n",
    "    \n",
    "    gen_dict_percent = {}\n",
    "    for genre in genre_dict: #transform the library values to percentages of total \n",
    "        average = (genre_dict[genre]/total)*100\n",
    "        rnd = round(average, 2)\n",
    "        gen_dict_percent[genre] = rnd\n",
    "    \n",
    "    return gen_dict_percent\n",
    " \n",
    "def sort_ft(dataset, index):\n",
    "    table = pop_genres(dataset, index)\n",
    "    sort_dict = []\n",
    "    for key in table: #sort the dictionary making a list of tuples from the dictionary\n",
    "        tup_data = (table[key], key)\n",
    "        sort_dict.append(tup_data) \n",
    "\n",
    "    table_sorted = sorted(sort_dict, reverse=True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "        \n",
    "#this code finds the average of the values in a dictionary to total values:\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, I wanted to determine the genre that is most popular by creating a frequency dictionary. \n",
    "The function `pop_genre` does the following: \n",
    "1. creates a dictionary frequency table from the specified list and index\n",
    "2. after the dictionary freq table is established, it converts the values in the dictionary to percentages by dividing by the `len(dataset)` then rounding to 2 decimal places\n",
    "\n",
    "The next function `sort_ft` sorts the returned percentage frequency table to a sorted form:\n",
    "1. take the stored percentage freq table from `pop_genre` and iterate to convert key, values to tuples\n",
    "2. then make a list of tuples\n",
    "3. finally, use the `sorted` function to sort high to low based on the percentage value\n",
    "4. last, print in the specified format for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games : 58.16\n",
      "Entertainment : 7.88\n",
      "Photo & Video : 4.97\n",
      "Education : 3.66\n",
      "Social Networking : 3.29\n",
      "Shopping : 2.61\n",
      "Utilities : 2.51\n",
      "Sports : 2.14\n",
      "Music : 2.05\n",
      "Health & Fitness : 2.02\n",
      "Productivity : 1.74\n",
      "Lifestyle : 1.58\n",
      "News : 1.33\n",
      "Travel : 1.24\n",
      "Finance : 1.12\n",
      "Weather : 0.87\n",
      "Food & Drink : 0.81\n",
      "Reference : 0.56\n",
      "Business : 0.53\n",
      "Book : 0.43\n",
      "Navigation : 0.19\n",
      "Medical : 0.19\n",
      "Catalogs : 0.12\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "adl_genres = sort_ft(adl_total_clean, 11)\n",
    "print(adl_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAMILY : 18.45\n",
      "GAME : 9.87\n",
      "TOOLS : 8.44\n",
      "BUSINESS : 4.59\n",
      "LIFESTYLE : 3.9\n",
      "PRODUCTIVITY : 3.89\n",
      "FINANCE : 3.7\n",
      "MEDICAL : 3.52\n",
      "SPORTS : 3.4\n",
      "PERSONALIZATION : 3.32\n",
      "COMMUNICATION : 3.24\n",
      "HEALTH_AND_FITNESS : 3.08\n",
      "PHOTOGRAPHY : 2.95\n",
      "NEWS_AND_MAGAZINES : 2.8\n",
      "SOCIAL : 2.66\n",
      "TRAVEL_AND_LOCAL : 2.34\n",
      "SHOPPING : 2.25\n",
      "BOOKS_AND_REFERENCE : 2.14\n",
      "DATING : 1.86\n",
      "VIDEO_PLAYERS : 1.78\n",
      "MAPS_AND_NAVIGATION : 1.4\n",
      "EDUCATION : 1.29\n",
      "FOOD_AND_DRINK : 1.24\n",
      "ENTERTAINMENT : 1.13\n",
      "LIBRARIES_AND_DEMO : 0.94\n",
      "AUTO_AND_VEHICLES : 0.93\n",
      "HOUSE_AND_HOME : 0.84\n",
      "WEATHER : 0.8\n",
      "EVENTS : 0.71\n",
      "ART_AND_DESIGN : 0.67\n",
      "PARENTING : 0.65\n",
      "COMICS : 0.62\n",
      "BEAUTY : 0.6\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gdl_genres = sort_ft(gdl_total_clean, 1)\n",
    "print(gdl_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools : 8.43\n",
      "Entertainment : 6.07\n",
      "Education : 5.35\n",
      "Business : 4.59\n",
      "Productivity : 3.89\n",
      "Lifestyle : 3.89\n",
      "Finance : 3.7\n",
      "Medical : 3.52\n",
      "Sports : 3.46\n",
      "Personalization : 3.32\n",
      "Communication : 3.24\n",
      "Action : 3.1\n",
      "Health & Fitness : 3.08\n",
      "Photography : 2.95\n",
      "News & Magazines : 2.8\n",
      "Social : 2.66\n",
      "Travel & Local : 2.32\n",
      "Shopping : 2.25\n",
      "Books & Reference : 2.14\n",
      "Simulation : 2.04\n",
      "Dating : 1.86\n",
      "Arcade : 1.85\n",
      "Video Players & Editors : 1.77\n",
      "Casual : 1.76\n",
      "Maps & Navigation : 1.4\n",
      "Food & Drink : 1.24\n",
      "Puzzle : 1.13\n",
      "Racing : 0.99\n",
      "Role Playing : 0.94\n",
      "Libraries & Demo : 0.94\n",
      "Auto & Vehicles : 0.93\n",
      "Strategy : 0.91\n",
      "House & Home : 0.84\n",
      "Weather : 0.8\n",
      "Events : 0.71\n",
      "Adventure : 0.68\n",
      "Comics : 0.61\n",
      "Beauty : 0.6\n",
      "Art & Design : 0.59\n",
      "Parenting : 0.5\n",
      "Card : 0.45\n",
      "Casino : 0.43\n",
      "Trivia : 0.42\n",
      "Educational;Education : 0.39\n",
      "Educational : 0.37\n",
      "Board : 0.37\n",
      "Education;Education : 0.34\n",
      "Word : 0.26\n",
      "Casual;Pretend Play : 0.24\n",
      "Music : 0.2\n",
      "Racing;Action & Adventure : 0.17\n",
      "Puzzle;Brain Games : 0.17\n",
      "Entertainment;Music & Video : 0.17\n",
      "Casual;Brain Games : 0.14\n",
      "Casual;Action & Adventure : 0.14\n",
      "Arcade;Action & Adventure : 0.12\n",
      "Action;Action & Adventure : 0.1\n",
      "Educational;Pretend Play : 0.09\n",
      "Board;Brain Games : 0.09\n",
      "Simulation;Action & Adventure : 0.08\n",
      "Parenting;Education : 0.08\n",
      "Entertainment;Brain Games : 0.08\n",
      "Parenting;Music & Video : 0.07\n",
      "Educational;Brain Games : 0.07\n",
      "Casual;Creativity : 0.07\n",
      "Art & Design;Creativity : 0.07\n",
      "Education;Pretend Play : 0.06\n",
      "Role Playing;Pretend Play : 0.05\n",
      "Education;Creativity : 0.05\n",
      "Role Playing;Action & Adventure : 0.03\n",
      "Puzzle;Action & Adventure : 0.03\n",
      "Entertainment;Creativity : 0.03\n",
      "Entertainment;Action & Adventure : 0.03\n",
      "Educational;Creativity : 0.03\n",
      "Educational;Action & Adventure : 0.03\n",
      "Education;Music & Video : 0.03\n",
      "Education;Brain Games : 0.03\n",
      "Education;Action & Adventure : 0.03\n",
      "Adventure;Action & Adventure : 0.03\n",
      "Video Players & Editors;Music & Video : 0.02\n",
      "Sports;Action & Adventure : 0.02\n",
      "Simulation;Pretend Play : 0.02\n",
      "Puzzle;Creativity : 0.02\n",
      "Music;Music & Video : 0.02\n",
      "Entertainment;Pretend Play : 0.02\n",
      "Casual;Education : 0.02\n",
      "Board;Action & Adventure : 0.02\n",
      "Video Players & Editors;Creativity : 0.01\n",
      "Trivia;Education : 0.01\n",
      "Travel & Local;Action & Adventure : 0.01\n",
      "Tools;Education : 0.01\n",
      "Strategy;Education : 0.01\n",
      "Strategy;Creativity : 0.01\n",
      "Strategy;Action & Adventure : 0.01\n",
      "Simulation;Education : 0.01\n",
      "Role Playing;Brain Games : 0.01\n",
      "Racing;Pretend Play : 0.01\n",
      "Puzzle;Education : 0.01\n",
      "Parenting;Brain Games : 0.01\n",
      "Music & Audio;Music & Video : 0.01\n",
      "Lifestyle;Pretend Play : 0.01\n",
      "Lifestyle;Education : 0.01\n",
      "Health & Fitness;Education : 0.01\n",
      "Health & Fitness;Action & Adventure : 0.01\n",
      "Entertainment;Education : 0.01\n",
      "Communication;Creativity : 0.01\n",
      "Comics;Creativity : 0.01\n",
      "Casual;Music & Video : 0.01\n",
      "Card;Action & Adventure : 0.01\n",
      "Books & Reference;Education : 0.01\n",
      "Art & Design;Pretend Play : 0.01\n",
      "Art & Design;Action & Adventure : 0.01\n",
      "Arcade;Pretend Play : 0.01\n",
      "Adventure;Education : 0.01\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gdl_genres = sort_ft(gdl_total_clean, 9)\n",
    "print(gdl_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Genre Data Analysis:\n",
    "\n",
    "In the three code cells above we ran each list through the `sort_ft` function.\n",
    "\n",
    "We got the return \n",
    "- **Games** as the most popular genre for the Apple store and **entertainment** as second most popular in the 'prime_genre' column\n",
    "- **Family** is most popular and **Game** is second most popular genre for the Google store in the 'Category' column\n",
    "- **Tools, entertainment, and education** were the three most popular genres in the Google store 'Genre' column respectively\n",
    "\n",
    "Keep in mind that these results are for **free** and **english language** apps in each store only. \n",
    "\n",
    "Recommendation could be to create an app that fits or could be included in all 4 cetegories that are #1 and #2 most popular between both stores. For example, a family friendly game that also fits into the entertainment category. \n",
    "\n",
    "It would be very interesting to see a dataset that breaks down the sub-categorys under games, especially in the Apply store. Since such a large overwhelming percentage of the apps are in the Apple Store are of the games genre a breakdown could provide more insight into the most popular type of games. i.e. puzzles, action, racing, etc. \n",
    "\n",
    "The Google store dataset does provide this breakdown. For example, the Google store dataset provides data for both 'genre' and 'category'. Further analysis suggests that categories are the primary grouping factor and genres are sub-groupings under category. For example an app could be in the game category with the genre of puzzle. \n",
    "\n",
    "The important thing to keep in mind is that the company needs to create an app that will be profitable. For the app genre, there are two choices. One is to make an app in a popular genre. the benefit here is that popular genres probably have more users and a greater chance of making a lot of money if the app becomes popular. The downside to this is that the most popular genres have a lot of competition therefor becoming noticed is like being one fish in the ocean. The app would have to be vestly superior to all the other free apps out there. It maybe wise in this scenario to go with a less popular genre in hopes to find a niche where there is a need for an app that many people need and there arent many options on the market. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Determine which type of apps have the most users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will determine which app types have the most users by genre. For the Apple Store we will use the 'user_ratings' column as a proxy for number of users. For the Google store, we will use 'installs' as number of users. \n",
    "\n",
    "In order to determine which genre is most popular among users, we will find the average ratings or installs. To find the average we will need to know the sum of all the ratings or installs for each app in a genre. The we must determine the number of apps in each genre. \n",
    "\n",
    "To find the sum of all ratings/installs in a genre we must use a dictionary of genres and our cleaned list. We will have to iterate over the dictionary with a nested iteration over the list to filter the data to ensure only apps of the same genre are being added up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apple Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Networking : 71548.34905660378\n",
      "Photo & Video : 28441.54375\n",
      "Games : 22788.6696905016\n",
      "Music : 57326.530303030304\n",
      "Reference : 74942.11111111111\n",
      "Health & Fitness : 23298.015384615384\n",
      "Weather : 52279.892857142855\n",
      "Utilities : 18684.456790123455\n",
      "Travel : 28243.8\n",
      "Shopping : 26919.690476190477\n",
      "News : 21248.023255813954\n",
      "Navigation : 86090.33333333333\n",
      "Lifestyle : 16485.764705882353\n",
      "Entertainment : 14029.830708661417\n",
      "Food & Drink : 33333.92307692308\n",
      "Sports : 23008.898550724636\n",
      "Book : 39758.5\n",
      "Finance : 31467.944444444445\n",
      "Education : 7003.983050847458\n",
      "Productivity : 21028.410714285714\n",
      "Business : 7491.117647058823\n",
      "Catalogs : 4004.0\n",
      "Medical : 612.0\n"
     ]
    }
   ],
   "source": [
    "#start with a previously defined function for the dictionary: \n",
    "adl_inst = pop_genres(adl_total_clean, 11)\n",
    "\n",
    "#iterate over the keys in `adl_inst`:\n",
    "for genre in adl_inst: \n",
    "    total = 0\n",
    "    len_total = 0\n",
    "    for row in adl_total_clean: #iterate over the list defining rating numbers and genres\n",
    "        rat = row[5]\n",
    "        gen = row[11]\n",
    "        if gen == genre: \n",
    "            rat = rat.replace(',', '')\n",
    "            rat = rat.replace('+', '')\n",
    "            rat = int(rat)\n",
    "            total += rat\n",
    "            len_total += 1\n",
    "    #find the average of the genre prior to iterating over the next key: \n",
    "    avg_user = total / len_total\n",
    "    print(genre, ':', avg_user)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ART_AND_DESIGN : 1937476.2711864407\n",
      "AUTO_AND_VEHICLES : 647317.8170731707\n",
      "BEAUTY : 513151.88679245283\n",
      "BOOKS_AND_REFERENCE : 8767811.894736841\n",
      "BUSINESS : 1712290.1474201474\n",
      "COMICS : 817657.2727272727\n",
      "COMMUNICATION : 38456119.167247385\n",
      "DATING : 854028.8303030303\n",
      "EDUCATION : 3082017.543859649\n",
      "ENTERTAINMENT : 21134600.0\n",
      "EVENTS : 253542.22222222222\n",
      "FINANCE : 1387692.475609756\n",
      "FOOD_AND_DRINK : 1924897.7363636363\n",
      "HEALTH_AND_FITNESS : 4188821.9853479853\n",
      "HOUSE_AND_HOME : 1313681.9054054054\n",
      "LIBRARIES_AND_DEMO : 638503.734939759\n",
      "LIFESTYLE : 1437816.2687861272\n",
      "GAME : 15837565.085714286\n",
      "FAMILY : 2691618.159021407\n",
      "MEDICAL : 120616.48717948717\n",
      "SOCIAL : 23253652.127118643\n",
      "SHOPPING : 7036877.311557789\n",
      "PHOTOGRAPHY : 17805627.643678162\n",
      "SPORTS : 3638640.1428571427\n",
      "TRAVEL_AND_LOCAL : 13984077.710144928\n",
      "TOOLS : 10695245.286096256\n",
      "PERSONALIZATION : 5201482.6122448975\n",
      "PRODUCTIVITY : 16787331.344927534\n",
      "PARENTING : 542603.6206896552\n",
      "WEATHER : 5074486.197183099\n",
      "VIDEO_PLAYERS : 24852732.40506329\n",
      "NEWS_AND_MAGAZINES : 9549178.467741935\n",
      "MAPS_AND_NAVIGATION : 4056941.7741935486\n"
     ]
    }
   ],
   "source": [
    "#start with a previously defined function for the dictionary: \n",
    "gdl_inst = pop_genres(gdl_total_clean, 1)\n",
    "\n",
    "#iterate over the keys in `adl_inst`:\n",
    "for genre in gdl_inst: \n",
    "    total = 0\n",
    "    len_total = 0\n",
    "    for row in gdl_total_clean: #iterate over the list defining rating numbers and genres\n",
    "        rat = row[5]\n",
    "        gen = row[1]\n",
    "        if gen == genre: \n",
    "            rat = rat.replace(',', '')\n",
    "            rat = rat.replace('+', '')\n",
    "            rat = int(rat)\n",
    "            total += rat\n",
    "            len_total += 1\n",
    "    #find the average of the genre prior to iterating over the next key: \n",
    "    avg_user = total / len_total\n",
    "    print(genre, ':', avg_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Conclusions:\n",
    "\n",
    "Based on the results obtained above in Step 1, we can see that the genres that contain the majority of apps are: \n",
    "- Games as the most popular genre for the Apple store and entertainment as second most popular in the 'prime_genre' column\n",
    "- Family is most popular and Game is second most popular genre for the Google store in the 'Category' column\n",
    "- Tools, entertainment, and education were the three most popular genres in the Google store 'Genre' column respectively\n",
    "\n",
    "The results from Step 2 indicate that in the Apple Store: \n",
    "- Navigation, Reference, and Social Networking were the genres that contained apps that were the most rated by users. Since rating was the proxy for number of users, these three genres contain the most popular apps in the store. \n",
    "And in the Google Store: \n",
    "-Social, video players, tools and communication were the genres with the highest average users in the Google store. \n",
    "\n",
    "Combining this information from Step 1 and 2 of the analysis section, a good strategy may be to avoid the genres that have the most apps in them because there is more competition and less likelyhood that the test app would be found amongst all the other apps in the genre. We might want to find a genre that is dominated by only a few apps in terms of users. The reason for this is that we can mimic that the extremely populaar app is doing without having a lot of competition in the space. \n",
    "\n",
    "Reviewing and comparing both results from step 2, a good strategy might be to pick an app that could be found in multiple genres that are less popular but not the least popular and can be applied in a unique way to give the user a new experience rather than a modified experience. For example, books/reference genre in Google store and books in Apple store and the travel genre in both stores are relatively less popular. A sprcific idea for an app might be something along the lines of an app that interfaces with your calendar to determine if you are going on any trips in the future and where you are going. Then it could give you book recommendations based on where you are going and what your reading preferences are. \n",
    "\n",
    "Recommendations for further analysis/research:\n",
    "Further analysis should be conducted to determine the most popualr apps from the genres that the company selects to build their app in and determine why those apps are so popular.\n",
    "\n",
    "The data cleaning process could be optimized to eliminate all non-English apps and retain those that are english but were removed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
